{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMhNrh0cImTkKcL1B8p1xuc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YeongRoYun/BearTeam/blob/edu/edu/model/YOLOv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/csm-kr/yolo_v2_vgg16_pytorch/blob/"
      ],
      "metadata": {
        "id": "RBoc4ATmLprh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xmltodict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7ke8u0zOX6f",
        "outputId": "c86c78ae-d900-49f3-8ca1-1bf3486266d7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: xmltodict\n",
            "Successfully installed xmltodict-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "LHPoBlGtinTP"
      },
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import xmltodict\n",
        "from PIL import Image\n",
        "from torchvision.datasets import VOCDetection\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import PILToTensor, Compose"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLO_PASCAL_VOC(VOCDetection):\n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(self.images[index]).convert('RGB')\n",
        "        \n",
        "        # img = img.resize((224,224))\n",
        "        img_transform = Compose([\n",
        "            PILToTensor(),\n",
        "            # Resize((224,224))\n",
        "        ])\n",
        "        img = torch.divide(img_transform(img), 255)\n",
        "        \n",
        "        target = xmltodict.parse(open(self.annotations[index], mode='rb'))\n",
        "        \n",
        "        classes = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\",\n",
        "                   \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
        "                   \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\",\n",
        "                   \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
        "        \n",
        "        label = torch.zeros(7, 7, 25, dtype = torch.float32)\n",
        "       \n",
        "        # Grid 만들기\n",
        "        Image_Height = float(target['annotation']['size']['height'])\n",
        "        Image_Width = float(target['annotation']['size']['width'])\n",
        "\n",
        "        try:\n",
        "            for i, obj in enumerate(target['annotation']['object']):\n",
        "                self.parse(obj, classes, Image_Width, Image_Height, label)\n",
        "    \n",
        "        # Single-Object in Image\n",
        "        except TypeError:\n",
        "            obj = target['annotation']['object']\n",
        "            self.parse(obj, classes, Image_Width, Image_Height, label)\n",
        "        return img, torch.tensor(label)\n",
        "    \n",
        "    def parse(self, obj, classes, Image_Width, Image_Height, label):\n",
        "        class_index = classes.index(obj['name'].lower())\n",
        "        \n",
        "        x_min = float(obj['bndbox']['xmin']) \n",
        "        y_min = float(obj['bndbox']['ymin'])\n",
        "        x_max = float(obj['bndbox']['xmax']) \n",
        "        y_max = float(obj['bndbox']['ymax'])\n",
        "        \n",
        "        x = (x_min + x_max) / 2.0\n",
        "        y = (y_min + y_max) / 2.0\n",
        "        w = x_max - x_min + 1\n",
        "        h = y_max - y_min + 1\n",
        "        \n",
        "        # 13 x 13 Grid!\n",
        "        cell_w = ceil(w / 13) # 마지막 셀의 크기는 다를 수 있다.\n",
        "        cell_h = ceil(h / 13)\n",
        "\n",
        "        cell_w_last = cell_w if w % 13 == 0 else w - (12 * cell_w)\n",
        "        cell_h_last = cell_h if h % 13 == 0 else h - (12 * cell_h)\n",
        "        \n",
        "\n",
        "        x_cell = int(x/cell_w) # int()는 floor와 동일하다!\n",
        "        y_cell = int(y/cell_h)\n",
        "        \n",
        "        x_val_inCell = float((x - x_cell * cell_w))\n",
        "        y_val_inCell = float((y - y_cell * cell_h))\n",
        "        \n",
        "        x_val_inCell = x_val_inCell / cell_w if x_cell < 12 \\\n",
        "                    else x_val_inCell / cell_w_last\n",
        "        y_val_inCell = y_val_inCell / cell_h if y_cell < 12 \\\n",
        "                    else y_val_inCell / cell_w_last\n",
        "        \n",
        "        # Bounding Box의 width와 height를 [0,1] 사이의 값으로 정규화 한다.\n",
        "        w = w / Image_Width\n",
        "        h = h / Image_Height\n",
        "        \n",
        "        # [x, y, w, h, c] 이후에 Class one-hot encoding이 있으므로, Offset을 5 준다.\n",
        "        class_index_inCell = class_index + 5\n",
        "        \n",
        "        # 한 Cell에서 Bounding Box는 하나만 가진다\n",
        "        label[y_cell][x_cell][0] = x_val_inCell\n",
        "        label[y_cell][x_cell][1] = y_val_inCell\n",
        "        label[y_cell][x_cell][2] = w\n",
        "        label[y_cell][x_cell][3] = h\n",
        "        # Object가 있는 것이 확실하므로 Confidence = 1.0이다.\n",
        "        label[y_cell][x_cell][4] = 1.0\n",
        "        \n",
        "        # 바운딩 박스의 중심점이 같은 셀에 위치하면, 이미지 자체를 복사해서 또다른 데이터로 만들어야 한다!\n",
        "        # 전처리 단계에서 이러한 경우는 제거된다고 가정한다.\n",
        "        label[y_cell][x_cell][class_index_inCell] = 1.0\n",
        "        return None"
      ],
      "metadata": {
        "id": "r92BlxOXLoGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLOv2(nn.Module):\n",
        "    def __init__(self, backbone, num_classes = 20):\n",
        "        \"\"\"\n",
        "        여기에서는 임의로 backbone을 VGG16을 유지한당\n",
        "        마지막 FC Layer를 포함한 온전한 VGG를 backbone으로 입력하기!\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_anchors = 5\n",
        "        self.num_classes = num_classes\n",
        "        # Backbone의 Parameters 고정! => 안할 수도 있다.\n",
        "        for feature in backbone.features[:-1]:\n",
        "            if type(feature) == type(nn.Conv2d(1, 1, 1)):\n",
        "                feature.requires_grad = False\n",
        "            else:\n",
        "                continue\n",
        "        self.backbone = backbone.features[:-1] \n",
        "        # Extra의 Output = [B, 512, ]\n",
        "        self.extra = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, 3, 1, 1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(inplace = True), # Memory 절약!\n",
        "            nn.Conv2d(512, 512, 3, 1, 1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True), \n",
        "            nn.Conv2d(512, 512, 3, 1, 1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d((2, 2)),\n",
        "        )\n",
        "        self.skip_module = nn.Sequential(\n",
        "            # 1 x 1 conv => channel만 변화!\n",
        "            nn.Conv2d(512, 64, 1, stride = 1, padding=0),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.final = nn.Sequential(\n",
        "            nn.Conv2d(768, 1024, 3, padding=1),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(1024, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            # 1 x 1 Convolution!\n",
        "            nn.Conv2d(256, self.num_anchors * (5 + self.num_classes), 1)\n",
        "        )\n",
        "        self.init_conv2d()\n",
        "        print(f\"num_params : {self.count_parameters()}\")\n",
        "\n",
        "    def init_conv2d(self):\n",
        "        mean = 0.0\n",
        "        std = 0.01\n",
        "        constant = 0.0\n",
        "        for c in self.extra.children():\n",
        "            if isinstance(c, nn.Conv2d):\n",
        "                nn.init.normal_(c.weight, mean, std)\n",
        "                nn.init.constant_(c.bias, constant)\n",
        "        for c in self.skip_module.children():\n",
        "            if isinstance(c, nn.Conv2d):\n",
        "                nn.init.normal_(c.weight, mean, std)\n",
        "                nn.init.constant_(c.bias, constant)\n",
        "        for c in self.final.children():\n",
        "            if isinstance(c, nn.Conv2d):\n",
        "                nn.init.normal_(c.weight, mean, std)\n",
        "                nn.init.constant_(c.bias, constant)\n",
        "        return None\n",
        "\n",
        "    def count_parameters(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # X : [B, C, H, W] 형태\n",
        "        \n",
        "        x = self.backbone(x) # O: B x 512 x H1 x W1 (H, W는 변한다!)\n",
        "        skip_x = self.skip_module(x) # O: 64 x H1 x W1\n",
        "\n",
        "        # skip_x 를 B x 64 x 26 x 26으로 맞춘다.\n",
        "        h = skip_x.size(2)\n",
        "        w = skip_x.size(3)\n",
        "\n",
        "        stride = 1\n",
        "        padding = [0, 0] # h, w\n",
        "        padding[0] = 0 if h - 25 > 0 else ceil(12.5 - 0.5 * h)\n",
        "        padding[1] = 0 if w - 25 > 0 else ceil(12.5 - 0.5 * w)\n",
        "\n",
        "        kernel = [0, 0] # h, w\n",
        "        kernel[0] = h - 25 if h - 25 > 0 else 2 * padding[0] + h - 25\n",
        "        kernel[1] = w - 25 if w - 25 > 0 else 2 * padding[1] + w - 25\n",
        "\n",
        "        skip_x = nn.MaxPool2d(kernel, stride, padding, )(skip_x) # B x 64 x 26 x 26!\n",
        "        print(skip_x.shape)\n",
        "        skip_x = skip_x.view(-1, 64, 13, 2, 13, 2)\n",
        "        skip_x = skip_x.permute(0, 3, 5, 1, 2, 4).contiguous() # B x 2 x 2 x 64 x 13 x 13으로!\n",
        "        skip_x = skip_x.view(-1, 256, 13, 13) # B x 256 x 13 x 13!!\n",
        "\n",
        "        x = self.extra(x) # B x 512 x H2 x W2\n",
        "        # B x 512 x 13 x 13으로 맞추기!\n",
        "        h = x.size(2)\n",
        "        w = x.size(3)\n",
        "\n",
        "        stride = 1\n",
        "        padding = [0, 0] # h, w\n",
        "        padding[0] = 0 if h - 12 > 0 else ceil(6 - 0.5 * h)\n",
        "        padding[1] = 0 if w - 12 > 0 else ceil(6 - 0.5 * w)\n",
        "\n",
        "        kernel = [0, 0] # h, w\n",
        "        kernel[0] = h - 12 if h - 12 > 0 else 2 * padding[0] + h - 12\n",
        "        kernel[1] = w - 12 if w - 12 > 0 else 2 * padding[1] + w - 12\n",
        "\n",
        "        x = nn.MaxPool2d(kernel, stride, padding, )(x) # B x 512 x 13 x 13!\n",
        "        print(x.shape)\n",
        "        # Concat\n",
        "        x = torch.cat([x, skip_x], dim=1) # B x 768 x 13 x 13\n",
        "        x = self.final(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "8su7oujsjBKT"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLOv2Loss(nn.Module):\n",
        "    \"\"\"\n",
        "    YOLOv1과 동일하게 구한당!!\n",
        "    단치 BBox = 5가 된것!!!\n",
        "    \"\"\"\n",
        "    pass"
      ],
      "metadata": {
        "id": "bdg_9GeGjHbl"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "from torchvision.models import vgg16_bn\n",
        "\n",
        "model = YOLOv2(vgg16_bn(weights='DEFAULT'))\n",
        "image = torch.randn([1, 3, 1920, 1200])\n",
        "y = model(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-MoxfnZTVD8",
        "outputId": "c790c5ea-81f4-4dd6-c9d3-ee2e69852bb0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_params : 31311741\n",
            "torch.Size([1, 64, 26, 26])\n",
            "torch.Size([1, 512, 13, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CJa3UqLPTUFK"
      }
    }
  ]
}