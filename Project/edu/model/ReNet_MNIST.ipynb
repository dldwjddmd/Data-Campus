{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96316697",
   "metadata": {},
   "source": [
    "# Renet\n",
    "https://github.com/NisTa24/ReNet-Implementation.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70028335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchdata.datapipes.map import SequenceWrapper\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomCrop, \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2556a7",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13417bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MNIST(root='./data', train=True, transform=Compose([\n",
    "    ToTensor(),\n",
    "    RandomCrop(14, ),\n",
    "]), download=True)\n",
    "test = MNIST(root='./data', train=False, transform=Compose([\n",
    "    ToTensor(),\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c215a7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "def do_kfold(dataset, k=2, batch_size=128):\n",
    "    '''\n",
    "    Input\n",
    "        dataset    : Pytorch Dataset\n",
    "        k          : The number of validation set\n",
    "        batch_size : The size of mini-batch\n",
    "        \n",
    "        => valid_size = k * batch_size\n",
    "        => train_size = batch_size * (total_length - k)\n",
    "    Return\n",
    "        train_loader, # DataLoader Type \n",
    "        valid_loader, # DataLoader Type\n",
    "    '''\n",
    "    data, targets = dataset.data, dataset.targets\n",
    "    dataset = list(zip(data, targets))\n",
    "    random.shuffle(dataset)\n",
    "    \n",
    "    sliced_idx = batch_size * k\n",
    "    valid_set, train_set = dataset[:sliced_idx], dataset[sliced_idx:]\n",
    "    \n",
    "    train_data, train_targets = zip(*train_set)\n",
    "    valid_data, valid_targets = zip(*valid_set)\n",
    "\n",
    "    train_dp = SequenceWrapper(train_data).zip(SequenceWrapper(train_targets))\n",
    "    valid_dp = SequenceWrapper(valid_data).zip(SequenceWrapper(valid_targets))\n",
    "    \n",
    "    train_loader = DataLoader(train_dp, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dp, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7add19",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f057886",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        X       : [batch_size, 1, 28(h), 28(w)]\n",
    "        Layer 1 :\n",
    "            Input_shape  : [b, 1, 28, 28]\n",
    "            Patch_size   : [1, 2, 2]\n",
    "            Vertically   : hidden_dim = 128, bidirectional = True(LSTM)\n",
    "            Patch_size   : [256, 1, 1]\n",
    "            Horizontally : hidden_dim = 128, bidirectional = True(LSTM)\n",
    "            Output_shape : [b, 256, 14, 14] # The hidden_dim * 2 is the number of output-channels\n",
    "        \n",
    "        Layer 2 :\n",
    "            Input_shape  : [b, 256, 14, 14]\n",
    "            Patch_size   : [256, 2, 2]\n",
    "            Vertically   : hidden_dim = 128, bidirectional = True(LSTM)\n",
    "            Patch_size   : [256, 1, 1]\n",
    "            Horizontally : hidden_dim = 128, bidirectional = True(LSTM)\n",
    "            Output_shape : [b, 256, 7, 7]\n",
    "        \n",
    "        Layer 3 :\n",
    "            [FC_Layer]\n",
    "            Input_shape  : [b, 256 * 7 * 7]\n",
    "            Output_shape : [b, 256 * 7 * 7]\n",
    "        \n",
    "        Layer 4 :\n",
    "            [FC_Layer]\n",
    "            Input_shape  : [b, 256 * 7 * 7]\n",
    "            Output_shape : [b, 10]\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.hidden_dim = 128\n",
    "        \n",
    "        self.layer1_v = nn.LSTM(1*2*2, self.hidden_dim, 1, True, True, 0, True)\n",
    "        self.layer1_h = nn.LSTM(256*1*1, self.hidden_dim, 1, True, True, 0, True)\n",
    "        \n",
    "        self.layer2_v = nn.LSTM(256*2*2, self.hidden_dim, 1, True, True, 0, True)\n",
    "        self.layer2_h = nn.LSTM(256*1*1, self.hidden_dim, 1, True, True, 0, True)\n",
    "        \n",
    "        self.fc_1 = nn.Linear(256*7*7, 256*7*7)\n",
    "        self.fc_2 = nn.Linear(256*7*7, 10)\n",
    "    \n",
    "    def _flatten_input(self, x, patch_size, direction):\n",
    "        '''\n",
    "        direction : \n",
    "            v : vertically\n",
    "            h : horizontally\n",
    "        Output :\n",
    "            shape : [[batch_size, seq_len, input_size], ...]\n",
    "        '''\n",
    "        x_b, _, x_h, x_w = x.shape\n",
    "        _, p_h, p_w = patch_size\n",
    "        assert (x_h % p_h) != 0 and (x_w % p_w) != 0\n",
    "        \n",
    "        match direction:\n",
    "            case 'v':\n",
    "                x = torch.split(x, x_h // p_h, dim=2)\n",
    "                x = [tmp.reshape(x_b, )]\n",
    "            case 'h':\n",
    "                x = torch.split(x, x_w // p_w, dim=3)\n",
    "        \n",
    "        \n",
    "        return inputs\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Input :\n",
    "            x : [batch_size(b), channel(c), height, width]\n",
    "        Flow. :\n",
    "            1 : Divide x into pathes, [b, c, Hp, Wp], Pij\n",
    "            2 : Flatten pathes, Pij : [b, Hp * c * Wp]\n",
    "            3 : Sweep pathes Vertically and Bidirectionally\n",
    "              : Patch size = [2, 2] fixed\n",
    "            5 : Sweep pathes Horizontally and Bidirectionally\n",
    "              : Patch size = [1, 1] fixed\n",
    "            6 : Repeat 3-4\n",
    "            7 : Flatten and FC Layer\n",
    "        \n",
    "        Additional\n",
    "            - By 3, implement pooling\n",
    "            - Each patch isn't overlapped at this model\n",
    "            - The number of FC-layer is 2\n",
    "        '''\n",
    "        inputs = self._flatten_input(x, (2, 2))\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c8bffe07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5],\n",
       "        [6, 7, 8, 9, 0]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3,4,5,6,7,8,9,0]).reshape(2, 5)\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
